{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados da Questão 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Resultados*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix size: 500x500\n",
    "- Sequential: 3.69053 seconds\n",
    "- 2 cores: 0.408077 seconds\n",
    "- 4 cores: 0.23933 seconds\n",
    "- 8 cores: 0.254502 seconds\n",
    "\n",
    "Matrix size: 1000x1000\n",
    "- Sequential: 33.2038 seconds\n",
    "- 2 cores: 3.44392  seconds\n",
    "- 4 cores: 1.93083 seconds\n",
    "- 8 cores: 1.91847 seconds\n",
    "\n",
    "Matrix size: 2000x2000\n",
    "- Sequential: 321.958 seconds\n",
    "- 2 cores: 42.4314 seconds\n",
    "- 4 cores: 19.9543 seconds\n",
    "- 8 cores: 22.3123 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Conclusão*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os resultados mostram que o uso de paralelismo com OpenMP é altamente eficaz em reduzir o tempo de execução para a multiplicação de matrizes, mas apresenta limitações dependendo do tamanho da matriz e do número de núcleos utilizados. \n",
    "\n",
    "Para matrizes menores, como as de tamanho 500x500, o paralelismo reduz significativamente o tempo de execução, mas os ganhos diminuem ao adicionar mais núcleos. O tempo de execução sequencial é de 3.69 segundos, enquanto com 2 núcleos cai para 0.408 segundos, e com 4 núcleos atinge 0.239 segundos. No entanto, com 8 núcleos, o tempo aumenta ligeiramente para 0.254 segundos, sugerindo que o overhead de sincronização começa a superar os ganhos com mais threads para tarefas pequenas.\n",
    "\n",
    "Para matrizes médias, como as de tamanho 1000x1000, o paralelismo demonstra uma escalabilidade clara até 4 núcleos. O tempo sequencial de 33.20 segundos é reduzido para 3.44 segundos com 2 núcleos e 1.93 segundos com 4 núcleos. No entanto, com 8 núcleos, o tempo de 1.91 segundos mostra ganhos marginais em relação a 4 núcleos, indicando saturação dos recursos de hardware, como cache e largura de banda de memória.\n",
    "\n",
    "Para matrizes grandes, como as de tamanho 2000x2000, o paralelismo ainda oferece benefícios significativos, reduzindo o tempo de execução sequencial de 321.95 segundos para 42.43 segundos com 2 núcleos e 19.95 segundos com 4 núcleos. Contudo, com 8 núcleos, o tempo aumenta para 22.31 segundos, evidenciando que o custo de sincronização e competição por recursos limita a escalabilidade para tamanhos muito grandes.\n",
    "\n",
    "Esses resultados indicam que o paralelismo é mais eficaz em tarefas de tamanho médio, onde a relação entre trabalho computacional e overhead está equilibrada. Para matrizes pequenas, o trabalho total é pequeno, e o custo de criação e sincronização de threads pode anular os ganhos. Para matrizes muito grandes, limitações de hardware, como largura de banda de memória e cache, começam a impactar o desempenho ao usar muitos núcleos.\n",
    "\n",
    "Portanto, a melhor configuração é usar até 4 núcleos para tarefas médias e grandes. Para tarefas muito grandes, técnicas adicionais, como multiplicação em blocos, podem ser necessárias para maximizar o uso eficiente dos recursos. Adicionar mais de 4 núcleos geralmente não traz ganhos significativos e, em alguns casos, pode até prejudicar o desempenho devido ao overhead adicional."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
