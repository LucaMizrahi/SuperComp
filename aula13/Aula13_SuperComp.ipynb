{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 13: Trabalhando com Schedulers no OpenMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nome: Luca Mizrahi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Parte 1: Schedules*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O tempo médio de execução do programa com escalonamento estático foi de 0.00000276 segundos\n",
      "\n",
      "O tempo médio de execução do programa com escalonamento dinâmico foi de 0.00000326 segundos\n",
      "\n",
      "O tempo médio de execução do programa com escalonamento guiado foi de 0.00000283 segundos\n",
      "\n",
      "O tempo médio de execução do programa com escalonamento automático foi de 0.00000233 segundos\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Static Scheduler\n",
    "t1_static = 2.838e-06 \n",
    "t2_static = 2.79e-06\n",
    "t3_static = 2.654e-06\n",
    "\n",
    "avg_static = (t1_static + t2_static + t3_static) / 3\n",
    "print(f'O tempo médio de execução do programa com escalonamento estático foi de {avg_static:.8f} segundos\\n')\n",
    "\n",
    "# Dynamic Scheduler\n",
    "t1_dynamic = 2.929e-06\n",
    "t2_dynamic = 3.385e-06\n",
    "t3_dynamic = 3.452e-06\n",
    "\n",
    "avg_dynamic = (t1_dynamic + t2_dynamic + t3_dynamic) / 3\n",
    "print(f'O tempo médio de execução do programa com escalonamento dinâmico foi de {avg_dynamic:.8f} segundos\\n')\n",
    "\n",
    "# Guided Scheduler\n",
    "t1_guided = 2.955e-06\n",
    "t2_guided = 2.589e-06\n",
    "t3_guided = 2.947e-06\n",
    "\n",
    "avg_guided = (t1_guided + t2_guided + t3_guided) / 3\n",
    "print(f'O tempo médio de execução do programa com escalonamento guiado foi de {avg_guided:.8f} segundos\\n')\n",
    "\n",
    "# Auto Scheduler\n",
    "t1_auto = 2.262e-06\n",
    "t2_auto = 2.369e-06\n",
    "t3_auto = 2.354e-06\n",
    "\n",
    "avg_auto = (t1_auto + t2_auto + t3_auto) / 3\n",
    "print(f'O tempo médio de execução do programa com escalonamento automático foi de {avg_auto:.8f} segundos\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-    Qual scheduler apresentou o menor tempo médio?\n",
    "\n",
    "De acordo com os resultados obtidos, o scheduler `auto` apresentou o menor tempo médio.\n",
    "\n",
    "-    Algum scheduler teve variações significativas entre as execuções? Se sim, por quê?\n",
    "\n",
    "Dynamic Scheduler teve a maior variação entre as execuções (0.523e-06 segundos). Isso provavelmente se deve ao fato de que o `dynamic` redistribui as tarefas conforme as threads terminam, o que pode gerar variações na carga de trabalho entre diferentes execuções.\n",
    "\n",
    "-    Alguma característica específica do trabalho (como carga de dados, balanceamento) parece ter influenciado o comportamento de um scheduler em particular?\n",
    "\n",
    "`Static` e Auto tiveram bom desempenho porque o trabalho era homogêneo, com tempos de execução semelhantes para todas as iterações. O escalonamento estático e a escolha automática do compilador minimizaram o overhead de redistribuição de tarefas. `Dynamic` teve um comportamento menos eficiente devido ao overhead de redistribuição dinâmica, o que não foi necessário neste caso de trabalho balanceado. `Guided` foi moderadamente eficiente, mas o overhead de alocar grandes blocos no início pode não ter compensado em um cenário onde todas as iterações têm tempos semelhantes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Parte 2: PI*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O tempo médio de execução do programa com MIN_BLK 1024 * 1024 * 256 foi de 0.76890772 segundos\n",
      "\n",
      "O tempo médio de execução do programa com MIN_BLK 1024 * 1024 * 1024 foi de 0.70162166 segundos\n",
      "\n",
      "O tempo médio de execução do programa com MIN_BLK 1024 * 1024 * 64 foi de 0.79253639 segundos\n",
      "\n",
      "O tempo médio de execução do programa com o número de tarefas determinado por MIN_BLK 1024 * 1024 * 256 foi de 0.81698716 segundos\n",
      "\n",
      "O tempo médio de execução do programa com o número de tarefas determinado por MIN_BLK 1024 * 1024 * 1024 foi de 1.26741315 segundos\n",
      "\n",
      "O tempo médio de execução do programa com o número de tarefas determinado por MIN_BLK 1024 * 1024 * 64 foi de 0.74263977 segundos\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rodando para diferentes valores de MIN_BLK \n",
    "# 1. MIN_BLK 1024 * 1024 * 256\n",
    "t1_1 = 1.43480676699983\n",
    "t2_1 = 0.436657729000217\n",
    "t3_1 = 0.435258654000791\n",
    "\n",
    "avg_1 = (t1_1 + t2_1 + t3_1) / 3\n",
    "print(f'O tempo médio de execução do programa com MIN_BLK 1024 * 1024 * 256 foi de {avg_1:.8f} segundos\\n')\n",
    "\n",
    "# 2. MIN_BLK 1024 * 1024 * 1024\n",
    "t1_2 = 1.27438930900007\n",
    "t2_2 = 0.416783306999605\n",
    "t2_3 = 0.413692354999512\n",
    "\n",
    "avg_2 = (t1_2 + t2_2 + t2_3) / 3\n",
    "print(f'O tempo médio de execução do programa com MIN_BLK 1024 * 1024 * 1024 foi de {avg_2:.8f} segundos\\n')\n",
    "\n",
    "# 3. MIN_BLK 1024 * 1024 * 64\n",
    "t1_3 = 1.39451379100046\n",
    "t2_3 = 0.448841694999828\n",
    "t3_3 = 0.534253672999512\n",
    "\n",
    "avg_3 = (t1_3 + t2_3 + t3_3) / 3\n",
    "print(f'O tempo médio de execução do programa com MIN_BLK 1024 * 1024 * 64 foi de {avg_3:.8f} segundos\\n')\n",
    "\n",
    "\n",
    "# Rodando para diferentes números de tarefas (modificando o MIN_BLK)\n",
    "# 1. MIN_BLK 1024 * 1024 * 256\n",
    "t1_1_task = 1.13160959299967\n",
    "t2_1_task = 0.67387111700009\n",
    "t3_1_task = 0.645480760000282\n",
    "\n",
    "avg_1_task = (t1_1_task + t2_1_task + t3_1_task) / 3\n",
    "print(f'O tempo médio de execução do programa com o número de tarefas determinado por MIN_BLK 1024 * 1024 * 256 foi de {avg_1_task:.8f} segundos\\n')\n",
    "\n",
    "# 2. MIN_BLK 1024 * 1024 * 1024\n",
    "t1_2_task = 1.60522679799942\n",
    "t2_2_task = 1.09677572299915\n",
    "t3_2_task = 1.10023693099993\n",
    "\n",
    "avg_2_task = (t1_2_task + t2_2_task + t3_2_task) / 3\n",
    "print(f'O tempo médio de execução do programa com o número de tarefas determinado por MIN_BLK 1024 * 1024 * 1024 foi de {avg_2_task:.8f} segundos\\n')\n",
    "\n",
    "# 3. MIN_BLK 1024 * 1024 * 64\n",
    "t1_3_task = 1.21905318499921\n",
    "t2_3_task = 0.53887051699985\n",
    "t3_3_task = 0.469995606000339\n",
    "\n",
    "avg_3_task = (t1_3_task + t2_3_task + t3_3_task) / 3\n",
    "print(f'O tempo médio de execução do programa com o número de tarefas determinado por MIN_BLK 1024 * 1024 * 64 foi de {avg_3_task:.8f} segundos\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### **1. Qual abordagem (parallel for ou tasks) apresentou melhor desempenho?**\n",
    "\n",
    "Vamos comparar as médias dos tempos de execução para `parallel for` e `omp task` com diferentes valores de `MIN_BLK`.\n",
    "\n",
    "#### **Média dos tempos com `parallel for`:**\n",
    "- **MIN_BLK = 1024 * 1024 * 256**: `avg_1 = 0.76890772` segundos\n",
    "- **MIN_BLK = 1024 * 1024 * 1024**: `avg_2 = 0.70162166` segundos\n",
    "- **MIN_BLK = 1024 * 1024 * 64**: `avg_3 = 0.79253639` segundos\n",
    "\n",
    "#### **Média dos tempos com `omp task`:**\n",
    "- **MIN_BLK = 1024 * 1024 * 256**: `avg_1_task = 0.81632049` segundos\n",
    "- **MIN_BLK = 1024 * 1024 * 1024**: `avg_2_task = 1.26741315` segundos\n",
    "- **MIN_BLK = 1024 * 1024 * 64**: `avg_3_task = 0.74263910` segundos\n",
    "\n",
    "#### **Conclusão:**\n",
    "- No geral, o **`parallel for`** apresentou melhor desempenho em comparação com **`omp task`** para os três valores de `MIN_BLK`.\n",
    "- O menor tempo de execução foi observado com **`parallel for`** e **MIN_BLK = 1024 * 1024 * 1024**, com uma média de `0.70162166` segundos.\n",
    "\n",
    "\n",
    "#### **2. O valor de `MIN_BLK` ou o número de tarefas influenciou significativamente o tempo de execução?**\n",
    "\n",
    "Sim, o valor de `MIN_BLK` influenciou significativamente o tempo de execução em ambos os casos (`parallel for` e `omp task`).\n",
    "\n",
    "#### **Impacto de `MIN_BLK` no `parallel for`:**\n",
    "- **MIN_BLK = 1024 * 1024 * 1024** apresentou o menor tempo médio (`0.70162166` segundos), enquanto **MIN_BLK = 1024 * 1024 * 64** apresentou o maior tempo médio (`0.79253639` segundos).\n",
    "- Isso sugere que, com um `MIN_BLK` maior, há menos overhead de criação de blocos e o paralelismo se beneficia de um trabalho mais bem distribuído entre as threads.\n",
    "\n",
    "#### **Impacto de `MIN_BLK` no `omp task`:**\n",
    "- **MIN_BLK = 1024 * 1024 * 1024** teve o maior tempo médio (`1.26741315` segundos), enquanto **MIN_BLK = 1024 * 1024 * 64** apresentou o menor tempo (`0.74263910` segundos).\n",
    "- No caso de **`omp task`**, um `MIN_BLK` muito grande parece gerar menos tarefas, o que leva a um menor aproveitamento do paralelismo e a um maior tempo de execução. Por outro lado, valores menores de `MIN_BLK` (como `64 MB`) geram mais tarefas, distribuindo melhor o trabalho entre as threads e melhorando o desempenho.\n",
    "\n",
    "#### **Conclusão:**\n",
    "- Para **`parallel for`**, o melhor desempenho foi obtido com um valor intermediário de **`MIN_BLK`** (`1024 * 1024 * 1024`).\n",
    "- Para **`omp task`**, o melhor desempenho foi com **`MIN_BLK` = 1024 * 1024 * 64**, pois mais tarefas foram criadas, aproveitando melhor o paralelismo.\n",
    "\n",
    "\n",
    "#### **3. Alguma abordagem teve variação maior entre execuções? Por quê?**\n",
    "\n",
    "#### **Variação no `parallel for`:**\n",
    "- As variações nos tempos de execução entre as três execuções foram relativamente pequenas em todos os casos:\n",
    "  - **MIN_BLK = 1024 * 1024 * 256**: Variação de `1.4348 s` a `0.4353 s`\n",
    "  - **MIN_BLK = 1024 * 1024 * 1024**: Variação de `1.2744 s` a `0.4137 s`\n",
    "  - **MIN_BLK = 1024 * 1024 * 64**: Variação de `1.3945 s` a `0.4488 s`\n",
    "\n",
    "  A variação no `parallel for` foi maior com valores de `MIN_BLK` menores, o que sugere que o overhead de dividir o trabalho em muitos blocos menores introduz alguma inconsistência no tempo de execução.\n",
    "\n",
    "#### **Variação no `omp task`:**\n",
    "- No `omp task`, as variações entre execuções foram maiores do que no `parallel for`:\n",
    "  - **MIN_BLK = 1024 * 1024 * 256**: Variação de `1.1316 s` a `0.6455 s`\n",
    "  - **MIN_BLK = 1024 * 1024 * 1024**: Variação de `1.6052 s` a `1.0968 s`\n",
    "  - **MIN_BLK = 1024 * 1024 * 64**: Variação de `1.2191 s` a `0.4700 s`\n",
    "\n",
    "  A maior variação foi observada com **MIN_BLK = 1024 * 1024 * 256** e **1024 * 1024 * 1024** para `omp task`. Isso ocorre porque a criação e sincronização de tarefas pode introduzir mais variabilidade entre execuções, especialmente com menos tarefas (quando `MIN_BLK` é grande).\n",
    "\n",
    "#### **Conclusão:**\n",
    "- **`omp task`** apresentou uma variação maior entre execuções, principalmente porque a criação dinâmica de tarefas e a sincronização entre elas introduz mais overhead e incerteza. Em valores maiores de `MIN_BLK`, com menos tarefas criadas, o aproveitamento do paralelismo é menor, e a variação tende a ser maior.\n",
    "- **`parallel for`** foi mais consistente, com variações menores entre execuções, já que a distribuição de trabalho é feita de maneira mais direta e previsível.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Parte 3: Manipulação de Efeitos Colaterais no Vetor*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O tempo médio de execução do programa com pragma omp critical e n = 10.000 foi de 0.04443967 segundos\n",
      "\n",
      "O tempo médio de execução do programa com pragma omp critical e n = 100.000 foi de 0.04441790 segundos\n",
      "\n",
      "O tempo médio de execução do programa com pragma omp critical e n = 1.000.000 foi de 0.26185500 segundos\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------\n",
      "O tempo médio de execução do programa com pré-alocação de memória e n = 10.000 foi de 0.04370973 segundos\n",
      "\n",
      "O tempo médio de execução do programa com pré-alocação de memória e n = 100.000 foi de 0.03930830 segundos\n",
      "\n",
      "O tempo médio de execução do programa com pré-alocação de memória e n = 1.000.000 foi de 0.04463833 segundos\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Manipulação Efeito Colateral - pragma omp critical\n",
    "# n = 10.000\n",
    "t1_1_critical = 0.0682947\n",
    "t2_1_critical = 0.0324366\n",
    "t3_1_critical = 0.0325877\n",
    "\n",
    "avg_1_critical = (t1_1_critical + t2_1_critical + t3_1_critical) / 3\n",
    "print(f'O tempo médio de execução do programa com pragma omp critical e n = 10.000 foi de {avg_1_critical:.8f} segundos\\n')\n",
    "\n",
    "# n = 100.000\n",
    "t1_2_critical = 0.0680015\n",
    "t2_2_critical = 0.0327173\n",
    "t3_2_critical = 0.0325349\n",
    "\n",
    "avg_2_critical = (t1_2_critical + t2_2_critical + t3_2_critical) / 3\n",
    "print(f'O tempo médio de execução do programa com pragma omp critical e n = 100.000 foi de {avg_2_critical:.8f} segundos\\n')\n",
    "\n",
    "# n = 1.000.000\n",
    "t1_3_critical = 0.364316\n",
    "t2_3_critical = 0.216628\n",
    "t3_3_critical = 0.204621\n",
    "\n",
    "avg_3_critical = (t1_3_critical + t2_3_critical + t3_3_critical) / 3\n",
    "print(f'O tempo médio de execução do programa com pragma omp critical e n = 1.000.000 foi de {avg_3_critical:.8f} segundos\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "# Manipulação Efeito Colateral - pré-alocação de memória\n",
    "# n = 10.000\n",
    "t1_1_mem = 0.066565\n",
    "t2_1_mem = 0.0323659\n",
    "t3_1_mem = 0.0321983\n",
    "\n",
    "avg_1_mem = (t1_1_mem + t2_1_mem + t3_1_mem) / 3\n",
    "print(f'O tempo médio de execução do programa com pré-alocação de memória e n = 10.000 foi de {avg_1_mem:.8f} segundos\\n')\n",
    "\n",
    "# n = 100.000\n",
    "t1_2_mem = 0.0664903\n",
    "t2_2_mem = 0.0321853\n",
    "t3_2_mem = 0.0192493\n",
    "\n",
    "avg_2_mem = (t1_2_mem + t2_2_mem + t3_2_mem) / 3\n",
    "print(f'O tempo médio de execução do programa com pré-alocação de memória e n = 100.000 foi de {avg_2_mem:.8f} segundos\\n')\n",
    "\n",
    "# n = 1.000.000\n",
    "t1_3_mem = 0.0689363\n",
    "t2_3_mem = 0.0315512\n",
    "t3_3_mem = 0.0334275\n",
    "\n",
    "avg_3_mem = (t1_3_mem + t2_3_mem + t3_3_mem) / 3\n",
    "print(f'O tempo médio de execução do programa com pré-alocação de memória e n = 1.000.000 foi de {avg_3_mem:.8f} segundos\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-    Qual abordagem teve melhor desempenho: omp critical ou pré-alocação de memória?\n",
    "\n",
    "-    O uso de omp critical adicionou muito overhead? Como você pode justificar isso?\n",
    "\n",
    "-    A ordem dos dados no vetor foi mantida em ambas as abordagens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Parte 4: Conclusão*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-    Resuma as principais conclusões com base nos resultados obtidos nos testes.\n",
    "\n",
    "*Resposta*: \n",
    "\n",
    "-    Qual abordagem geral você considera mais eficiente para problemas recursivos e com efeitos colaterais?\n",
    "\n",
    "*Resposta*:\n",
    "\n",
    "-    Alguma técnica apresentou resultados inesperados? O que poderia explicar isso?\n",
    "\n",
    "*Resposta*:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
